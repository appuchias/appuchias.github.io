---
title: 'Mi razonamiento sobre "las IAs"'
description: 'Mis opiniones una vez m치s y (m치s concretamente sobre los LLMs) cu치ndo considero que usarlos es positivo'
author: Appuchia
date: 2025-02-10
categories:
  - Opinion
tags:
  - AI
  - LLM
draft: true
---

Casi que no comento nada sobre qu칠 son y esas cosas que se suelen poner de relleno
al principio de las publicaciones para retener m치s a la gente, a estas alturas
no creo que haya mucha gente que no haya o칤do "IA" o "red neuronal" m치s de 20 veces.

No tengo anuncios as칤 que no gano nada si me lees durante m치s tiempo y cuanto menos
te lleve, m치s tiempo tienes para otras cosas.

Ah, una cosa m치s antes de empezar, a los "modelos grandes de lenguaje" les voy
a llamar LLMs, por sus siglas en ingl칠s, por comodidad, porque nunca he escuchado
a nadie usar siglas en castellano y ya que hay "un est치ndar" pues lo uso (desarrollo
abajo lo que son, por ahora sigue leyendo).
Usar칠 IAs y LLMs entremezclados, pero casi siempre me referir칠 a los modelos de lenguaje.

Ahora s칤.

## Mi punto

Evidentemente las IAs son herramientas muy 칰tiles, especialmente usadas en ciertos
campos en las que se puedan emplear para tomar decisiones en aspectos dif칤ciles de
detectar para un ser humano, o para emplearlas como modelos y poder predecir valores.

Pero esto son m치s bien las IAs "tradicionales", me refiero, no es la tecnolog칤a de
la que est치 hablando todo el mundo todos los d칤as (muy a mi pesar), ese puesto se
lo llevan los LLMs, cosas como Claude, los distintos GPT y la multitud de modelos
abiertos que existen (ejem ejem _"""OpenAI"""_ ejem ejem).

No hay nada de malo en s칤 mismo en estos modelos, son una herramienta m치s que tiene
la ventaja de ser accesible usando solo lenguaje natural, sin tener que darle datos
codificados de ninguna manera concreta ni buscar empleando palabras clave ni tener
respuestas que son n칰meros decimales, por decir algo.

Este post viene de alguien que lleva usando GitHub copilot desde la beta gratuita,
que ha hecho alg칰n proyecto casi exclusivamente usando IAs y que est치 en un punto
de m치s odio que amor.

Empiezo por lo malo:

## Las pegas

El problema que le veo es, por un lado, la eficiencia (energ칠tica principalmente),
la calidad de las respuestas y la dependencia a los modelos.

### Eficiencia de los LLMS

#### Energ칠tica

El primer factor y uno de los m치s grandes es el tema energ칠tico.
Los LLMs consumen cantidades absolutamente descomunales de energ칤a para responder
a las preguntas m치s simples que se te ocurran.
Son redes enormes con cantidades muy grandes de valores que tener en memoria (consume
energ칤a y requiere componentes caros y dif칤ciles de refrigerar) y que (normalmente)
activan todas las partes de la red para todas las consultas[^1].

Hace no mucho, en un v칤deo comentaban que una consulta del "modelo de razonamiento"
m치s avanzado de OpenAI (segunda menci칩n y ninguna buena xd) equival칤a en emisiones
de CO2 a 5 dep칩sitos de gasolina, que, en caso de ser cierto, es una absoluta barbaridad
y completamente insostenible.
Si encuentro la fuente la a침adir칠 tambi칠n, que no me gusta dejar cosas sin documentar.

#### De uso

Por otro lado, me preocupa la eficiencia al usarlos, ahora se est치 normalizando el
hacerle una consulta y esperar pacientemente a que devuelva una respuesta no
muy buena, y a partir de ah칤 ir llevando al modelo a que te responda lo que buscabas
en un principio.
En vez de buscar la informaci칩n en un motor de b칰squeda hecho espec칤ficamente para
encontrar informaci칩n en base a peque침as "pistas" que obtiene con lo que buscas,
lo que es cada vez m치s habitual es buscar esa informaci칩n en los pesos de la red
como quien dice.

Y s칤, s칠 que si buscas una respuesta r치pida y concisa es muy 칰til y probablemente
m치s r치pido que un buscador, pero muchos usos no son ese, y por otro lado tampoco
puedes tener confianza completa en la respuesta, pero eso lo desarrollo m치s adelante.

Soy consciente de que existen servicios que integran los LLMs en programas que los
hacen m치s pr치cticos (los LLMs, los programas no son mejores por tener un "asistente"
que no sabe contar las Rs en "strawberry"[^2])

### Calidad de las respuestas

A estas alturas ya se sabe bastante, pero las respuestas de un LLM no son muy
precisas exactamente.

Por lo general responden decentemente bien, es lo que se consigue prediciendo la
siguiente palabra de una frase, pero en cuanto la complejidad de la pregunta
aumenta y no se le pide conocimiento que haya visto previamente, sino una versi칩n
espec칤fica de algo que est치s haciendo nuevo, muchas veces es incapaz de generar
una buena respuesta ni a la primera, ni a la segunda ni tras varios intentos.

Este aspecto se desarrolla m치s en [este v칤deo](https://www.youtube.com/watch?v=6Lxk9NMeWHg):

{{< youtube 6Lxk9NMeWHg >}}

Tambi칠n existen las alucinaciones, cuando se inventa completamente la respuesta
juntando palabras que gramaticalmente son correctas y forman frases que podr칤an
ser ciertas pero en realidad no lo son.

En el peor de los casos generar치 una respuesta a simple vista razonable pero completamente
falsa.

Enlazando esto con el punto anterior, cada respuesta inapropiada implica que todo
el consumo energ칠tico necesario para generarla es in칰til y "se tira a la basura"
porque no resuelve la consulta inicial e implica otra petici칩n m치s con su
correspondiente coste.

Otra cosa a tener en cuenta es que las respuestas son por la propia definici칩n
del modelo mediocres.
Los LLMs van concatenando la mejor palabra para continuar la serie una detr치s
de otra, pero su criterio para elegir la mejor en cada caso se basa en escoger
la palabra con mayor probabilidad.
En caso de que las opciones se distribuyeran bajo una distribuci칩n normal,
consistir칤a en tomar la media, que deja nada m치s y nada menos que un 50% de
palabras a su derecha, que ser칤an las opciones de mejores textos, pero m치s
improbables.

### Explicabilidad

Las IAs no son explicables.

Nada nuevo, espero.

Existen los ["sparse autoencoders"](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html)
y todo lo que t칰 quieras, pero no te vas a poner a mirar todos los pesos y
a partir de ellos intentar averiguar lo que est치 haciendo una red neuronal
como s칤 puedes hacer muy f치cilmente con cualquier modelo param칠trico """tradicional""".

Fin del argumento b치sicamente, por qu칠 deber칤as fiarte de lo que dice si,
aunque acierte mucho, no sabe decirte por qu칠?

C칩mo vas a seguir esas instrucciones si la 칰nica explicaci칩n que puedes dar
de estarlas siguiendo es "me lo dijo la IA" (y no sabes por qu칠)?

Habr치 casos donde no te importe demasiado, pero no se pueden tomar decisiones
importantes que afecten a personas sin motivo aparente.

### Dependencia y coste a las personas

El problema serio es cuando se empieza a depender de herramientas externas para
el desarrollo propio, especialmente cuando esas herramientas est치n ligadas a
empresas que evidentemente solo buscan beneficios y a칰n encima las herramientas
son tan poco fiables como los LLMs.

Y no me refiero a desarrollo solo en el sentido de la programaci칩n, que es en el
que me centrar칠 porque existen multitud de herramientas espec칤ficas, pero no es
el 칰nico afectado ni necesariamente el peor.

Depender de herramientas que no controlas es peligroso porque tu progreso est치
ligado al progreso de esa herramienta, y en caso de que se estanque, puedes
encontrarte sin medios para seguir avanzando.

Un s칤ntoma de ser "dependiente" de las IAs es lo que ThePrimeagen llama en sus
v칤deos "the copilot pause", la espera de uno o dos segundos despu칠s de empezar
a escribir una l칤nea de c칩digo, pretendiendo que Copilot la autocomplete por ti,
aunque sea la l칤nea m치s simple del mundo.

Es algo especialmente cierto en etapas de aprendizaje, donde usar las IAs para
evitar pensar algunas respuestas hace que no se interioricen los conceptos que
se trabajan.
En en caso de la programaci칩n, emplear c칩digo hecho por IAs y juntarlo de la mejor
manera posible para que funcione crea una aplicaci칩n con c칩digo que no conoces
porque no lo has escrito t칰 y que tampoco sabes mantener porque no existe ninguna
justificaci칩n para las decisiones que es necesario tomar cuando se implementa
una funcionalidad de una manera concreta.

Considero que pelearse con el c칩digo y "perder" horas averiguando c칩mo hacer que
funcione algo en lo que llevas ya un par de d칤as hace que entiendas a fondo
c칩mo funciona el lenguaje o la librer칤a con la que trabajas, leer documentaci칩n
se est치 perdiendo y me parece que es la mejor forma de entender c칩mo funciona
algo para poder usarlo con todo su potencial sin las limitaciones de usar una
IA como intermediaria.

La programaci칩n consiste principalmente en resolver problemas, y la parte m치s
importante al aprender a programar es enfrentarse a esos problemas y poder desarrollar
m칠todos para dividirlos y encontrar soluciones con las restricciones que tengas para
cada problema concreto.
Usar una IA para que haga la parte dif칤cil de ese proceso, encontrar una soluci칩n
al problema, boicotea el aprendizaje ya que, s칤, has encontrado la soluci칩n, pero
te has perdido la parte estimulante intermedia de ir encontrando el camino correcto
poco a poco, cada nuevo intento con menos errores y m치s capacidad para encontrarlos.

Adem치s de que un problema en programaci칩n normalmente tiene infinidad de soluciones
posibles, y el valor de cada una es el razonamiento que hay detr치s de ella.

### Otra consideraci칩n

Esta idea no es m칤a de todo, pero me pareci칩 razonable y considero que viene a cuento.

Hasta hace nada los modelos m치s potentes los ten칤an empresas privadas, y pretenden
venderlos como la tecnolog칤a que lo hace todo.

Si realmente su tecnolog칤a fuese capaz de crear de todo, por qu칠 la estar칤an vendiendo
y no la estar칤an usando para crear todos los productos posibles?

Como nota graciosa, Anthropic, los creadores de Claude, otro LLM, est치n pidiendo
que la gente no use IAs en las entrevistas de trabajo. \
Un poco ir칩nico, no? \
(Que lidien con el problema que han ayudado a crear, no?) \
[Fuente](https://arstechnica.com/ai/2025/02/irony-alert-anthropic-says-applicants-shouldnt-use-llms/)
(Archivada en [Web Archive](https://web.archive.org/web/20250211014848/https://arstechnica.com/ai/2025/02/irony-alert-anthropic-says-applicants-shouldnt-use-llms/)).

Otro v칤deo que he visto entre empezar a escribir el post y publicarlo, que trata
tambi칠n este tema: [enlace](https://youtu.be/pEREuWkesrQ?si=N5zGjGsOUJWvHGG7).

Esto tambi칠n aplica aunque m치s de lejos al tema de "la IA nos va a quitar el trabajo",
como digo justo aqu칤 debajo, los LLMs est치n muy bien para eliminar las partes repetitivas,
pero eso es lo que lleva ocurriendo con la automatizaci칩n desde hace bastante m치s
tiempo de lo que existen las IAs. \
Pero bueno, no es el tema de este post.
Mi opini칩n en eso es que si eres bueno en lo que haces no deber칤as estar muy preocupado
por las IAs, deber칤as estar preocupado en seguir siendo bueno.

Lo desarrollo un poco: \
Independientemente de lo que ocurra con las IAs ahora, lo deseable ser칤a poder sentirse
capaz de poder hacer cosas, o al menos de intentar hacerlas, con las herramientas
que haya.
Ahora damos por hecho herramientas que al aparecer no fueron bien recibidas solo
por ser nuevas, pero hoy es normal usarlas y hasta raro que no se usen.
Mucha gente aprendi칩 a programar sin ellas y muchos aprenden con ellas, y al final
lo importante no suele ser la herramienta que usas para arreglar el problema, sino
que el problema est치 arreglado. \
Considero que si te preocupas en aprender y en buscarte la vida para aprender, y
encontrar respuestas por tu cuenta, no te costar치 adaptarte a los problemas que surjan
en el futuro y adaptar tus herramientas a lo que sea que haga falta hacer.

## Las partes buenas

Alguna ten칤an que tener, digo yo.

Creo que resumo todo en un apartado:

### Productividad

Contradictorio, verdad?

Programando, los LLMs son extremadamente 칰tiles para escribir "boilerplate", c칩digo
repetitivo necesario para funcionar pero que no aporta la funcionalidad en s칤.
Por ejemplo, en Python cuando creas una clase, son necesarias ciertas definiciones
que son siempre id칠nticas:

```python
class Sedan(Coche):
  def __init__(self, puertas: int = 5):  # Por ejemplo
    super().__init__()

    ...
```

Pero esto se soluciona f치cilmente con snippets, "automatizaciones" que te autocompletan
parte del c칩digo cuando pones ciertas palabras clave, 칰til por ejemplo para:

```python
if __name__ == "__main__":
  ...
```

Pero no siempre es una sustituci칩n constante lo que hace falta, como en esos casos.
Para soluciones m치s "din치micas", como escribir un algoritmo simple ya existente,
la complejidad est치 "resuelta", y si conoces el algoritmo, pasarlo a c칩digo es m치s
una tarea mec치nica que algo que aporte valor en s칤 mismo.

Para esos casos, usar IAs en los editores de c칩digo es s칰per 칰til.
Ahorras todo el tiempo que dedicas a las tareas "mec치nicas" sin perder libertad en
el resto.

Pero no hay que dejarse llevar sin m치s, he restringido bastante ese caso de uso
conscientemente, porque ese es el caso para el que considero que realmente aportan
valor, usarlas b치sicamente como autocompletado de c칩digo algo m치s inteligente.

Mantengo mis opiniones anteriores de que consumen demasiada energ칤a y las respuestas
son, de primeras, malas, y es necesario revisarlas antes de aceptarlas, igual que
no aceptar칤as c칩digo de un becario sin antes repasarlo antes de fiarte de 칠l.

## Condiciones

Mi principal condici칩n para todo lo que pongo ah칤 arriba es la ejecuci칩n local
de los modelos.

Deepseek ha demostrado hace nada que se pueden ejecutar modelos de lenguaje de
mucha potencia con hardware m치s modesto que las granjas de las grandes empresas.
Pero antes de Deepseek ya exist칤an modelos abiertos muy capaces, como llama, mistral
y muchos otros.

Existe [ollama](https://ollama.com/), un proyecto que te permite usar modelos abiertos
en tu ordenador, y no, no hace falta tener hardware de la NASA. \
Cuanto m치s nueva la gr치fica mejor como norma general, pero hay [modelos funcionando
incluso en Raspberry Pis!](https://www.youtube.com/watch?v=o1sN1lB76EA).

## Conclusiones

Es una tecnolog칤a muy nueva y es dif칤cil medir el uso todav칤a, y es razonable.

No creo que las IAs se vayan a ir al menos a corto plazo, as칤 que soy de la opini칩n
de que es mejor entenderlas, saber usarlas y sacarles todo el beneficio posible. \
Pero me parece a칰n m치s importante recordar que son una herramienta m치s, igual que
muchas otras, y no tiene que condicionar tu forma de trabajar ni restringir tu avance.

---

Gracias por leerme!

Hecho con 游둯 por Appu.

[^1]: Los [modelos "Mixture of Experts" (MoE)](https://en.wikipedia.org/wiki/Mixture_of_experts) emplean "peque침as redes especializadas"
  en 치reas concretas del conocimiento y seleccionan los "expertos" relevantes que emplear en cada consulta y
  as칤 evitar la sobrecarga de partes de la red que no le aportan informaci칩n 칰til
  (p.ej. usar la "parte de matem치ticas" de un LLM para escribir un poema).
[^2]: Hasta hace bastante poco, los GPT eran incapaces de decir con precisi칩n el n칰mero de Rs
  que contiene la palabra "strawberry", y cuando dec칤a bien cu치ntas hab칤a, le preguntabas
  d칩nde y a veces se침alaba 4 Rs.
  De hecho, OpenAI incluy칩 en su lanzamiento de o1 un ejemplo donde las contaba bien.
  ![OpenAI consigue obtener la cantidad de Rs en strawberry](/images/2025/IAs/OpenAI_o1_strawberry.png)
  [Fuente](https://openai.com/index/learning-to-reason-with-llms/)
